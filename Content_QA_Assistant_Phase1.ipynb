{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f210db0c-93cc-4424-97f3-9c87e80a67d6",
   "metadata": {},
   "source": [
    "# Content QA Assistant â€“ Phase 1\n",
    "Rule-based pre-QA checks for content quality and compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "226e0a07-4c2b-437b-9376-9da153abe3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleData = \"\"\"\n",
    "This page describes a product.\n",
    "Click here to learn more about it.\n",
    "\n",
    "Benefits are amazing and guranteed.\n",
    "\n",
    "Sign up today to avail the offers.\n",
    "\n",
    "Here are the terms and condition, please click and check.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a31757b-63c8-4b30-8f72-414cebabdebb",
   "metadata": {},
   "source": [
    "First QA rule (Function)\n",
    "Rule: Check for a mandatory disclaimer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a3a931b-0d44-4351-b782-6900131047f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_disclaimer(text):\n",
    "    return \"not a medical advice\" in text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa9cab5a-0174-4319-9132-bfe8a5963a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_disclaimer(sampleData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67879d5-54e4-460b-ad96-8078ff1be092",
   "metadata": {},
   "source": [
    "What you just learned:\n",
    "\n",
    "Functions return values\n",
    "\n",
    ".lower() avoids case issues\n",
    "\n",
    "Boolean logic drives QA decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb00171-7ffa-4a6e-ad09-8bd1df90be40",
   "metadata": {},
   "source": [
    "Step 3 : Another Rule: Banned Phrase Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f910422-2450-4b1f-9440-1367bb752844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_banned_phrase(text):\n",
    "    bannedPhrase = ['click here','guranteed', 'click and check']\n",
    "    for banned in text:\n",
    "        if banned in text.lower():\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12c45281-f1cd-4213-8cc8-5dfb80aa04fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_banned_phrase(sampleData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03c3f82-e1b3-4354-9485-0734902b557a",
   "metadata": {},
   "source": [
    "Step 4: Store QA Issues\n",
    "#### Create a list named \"issues\" then call the above 2 functions created which will pass the \"sampleData\" string and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1dacf416-a66b-44e7-abaa-0f5ff1558913",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = []\n",
    "\n",
    "if not has_disclaimer(sampleData):\n",
    "    issues.append({\n",
    "        \"severity\":\"High\",\n",
    "        \"category\":\"Compliance\",\n",
    "        \"message\":\"Missing compliance message\"\n",
    "    })\n",
    "if has_banned_phrase(sampleData):\n",
    "    issues.append({\n",
    "        \"severity\":\"Medium\",\n",
    "        \"category\":\"Content\",\n",
    "        \"message\":\"Has banned phrase in the content\"\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330db320-eb50-40e0-9135-2bc740c494fd",
   "metadata": {},
   "source": [
    "#call the issues list now to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a534f6b-1202-4b09-82c2-05847385648f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'severity': 'High',\n",
       "  'category': 'Compliance',\n",
       "  'message': 'Missing compliance message'},\n",
       " {'severity': 'Medium',\n",
       "  'category': 'Content',\n",
       "  'message': 'Has banned phrase in the content'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c37e26-eed4-45a1-abde-dbcc79058e87",
   "metadata": {},
   "source": [
    "STEP5 :  Print Clean QA Report\n",
    "### We will loop through the \"issues\" and then will print a consice clean QA report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0df79adf-bb12-4be5-a88c-fcd57a2b9a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------QA Report-----------\n",
      "---------------------\n",
      "[High] Compliance - Missing compliance message\n",
      "[Medium] Content - Has banned phrase in the content\n"
     ]
    }
   ],
   "source": [
    "print(\"--------QA Report-----------\")\n",
    "print(\"---------------------\")\n",
    "for issue in issues:\n",
    "    print(f\"[{issue['severity']}] {issue['category']} - {issue['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8ddb33-eb90-4456-9755-86a414e32006",
   "metadata": {},
   "source": [
    "----\n",
    "###  Step 6: Add a QA score \n",
    "###  We will create a variable score and assign 100 by default\n",
    "### We will create a for loop and loop through issues, if the deverity is High then we will reduce score of 30 , if the score is Medium then we will reduce score of 15\n",
    "### Finally if the score is greater than or equal to 80 we will pass the content else we will fail the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9aeded9-650b-4c30-94a3-80dd2f494042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String passsed : \n",
      "This page describes a product.\n",
      "Click here to learn more about it.\n",
      "\n",
      "Benefits are amazing and guranteed.\n",
      "\n",
      "Sign up today to avail the offers.\n",
      "\n",
      "Here are the terms and condition, please click and check.\n",
      "\n",
      "QA Checklist : [{'severity': 'High', 'category': 'Compliance', 'message': 'Missing compliance message'}, {'severity': 'Medium', 'category': 'Content', 'message': 'Has banned phrase in the content'}]\n",
      "QA Score:55\n",
      "Status: FAIL\n"
     ]
    }
   ],
   "source": [
    "score = 100\n",
    "for issue in issues:\n",
    "    if issue[\"severity\"] == \"High\":\n",
    "        score = score - 30\n",
    "    elif issue[\"severity\"] == \"Medium\":\n",
    "        score = score - 15\n",
    "if score >=80:\n",
    "    status = \"PASS\"\n",
    "else:\n",
    "    status = \"FAIL\"\n",
    "print(f\"String passsed : {sampleData}\")\n",
    "print(f\"QA Checklist : {issues}\")\n",
    "has_banned_phrase(sampleData)\n",
    "has_disclaimer(sampleData)\n",
    "print(f\"QA Score:{score}\")\n",
    "print(f\"Status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c120d915-cda3-4960-a1ce-1ceca75d009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(issues):\n",
    "    score = 100\n",
    "\n",
    "    for issue in issues:\n",
    "        severity = issues[\"severity\"]\n",
    "\n",
    "        if severity == \"High\":\n",
    "            score = score - 30\n",
    "        elif severity == \"Medium\":\n",
    "            score = score - 15\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "574a1afa-24aa-420b-84fd-0ce6983ab71b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m score = \u001b[43mcalculate_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43missues\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Passing the above issues list created to the function as it already looped through the data of provided text\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mcalculate_score\u001b[39m\u001b[34m(issues)\u001b[39m\n\u001b[32m      2\u001b[39m score = \u001b[32m100\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m issue \u001b[38;5;129;01min\u001b[39;00m issues:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     severity = \u001b[43missues\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseverity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m severity == \u001b[33m\"\u001b[39m\u001b[33mHigh\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      8\u001b[39m         score = score - \u001b[32m30\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "score = calculate_score(issues) # Passing the above issues list created to the function as it already looped through the data of provided text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f610c1-0142-4163-9443-c61a8d7eb3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
